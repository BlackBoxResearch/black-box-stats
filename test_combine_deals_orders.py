TOKEN = 'eyJhbGciOiJSUzUxMiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiIyYTY2MGNmN2Q0ZWRlZDUzNzgwYTI2ZDcxODk2MjQ3NCIsInBlcm1pc3Npb25zIjpbXSwiYWNjZXNzUnVsZXMiOlt7ImlkIjoidHJhZGluZy1hY2NvdW50LW1hbmFnZW1lbnQtYXBpIiwibWV0aG9kcyI6WyJ0cmFkaW5nLWFjY291bnQtbWFuYWdlbWVudC1hcGk6cmVzdDpwdWJsaWM6KjoqIl0sInJvbGVzIjpbInJlYWRlciIsIndyaXRlciJdLCJyZXNvdXJjZXMiOlsiKjokVVNFUl9JRCQ6KiJdfSx7ImlkIjoibWV0YWFwaS1yZXN0LWFwaSIsIm1ldGhvZHMiOlsibWV0YWFwaS1hcGk6cmVzdDpwdWJsaWM6KjoqIl0sInJvbGVzIjpbInJlYWRlciIsIndyaXRlciJdLCJyZXNvdXJjZXMiOlsiKjokVVNFUl9JRCQ6KiJdfSx7ImlkIjoibWV0YWFwaS1ycGMtYXBpIiwibWV0aG9kcyI6WyJtZXRhYXBpLWFwaTp3czpwdWJsaWM6KjoqIl0sInJvbGVzIjpbInJlYWRlciIsIndyaXRlciJdLCJyZXNvdXJjZXMiOlsiKjokVVNFUl9JRCQ6KiJdfSx7ImlkIjoibWV0YWFwaS1yZWFsLXRpbWUtc3RyZWFtaW5nLWFwaSIsIm1ldGhvZHMiOlsibWV0YWFwaS1hcGk6d3M6cHVibGljOio6KiJdLCJyb2xlcyI6WyJyZWFkZXIiLCJ3cml0ZXIiXSwicmVzb3VyY2VzIjpbIio6JFVTRVJfSUQkOioiXX0seyJpZCI6Im1ldGFzdGF0cy1hcGkiLCJtZXRob2RzIjpbIm1ldGFzdGF0cy1hcGk6cmVzdDpwdWJsaWM6KjoqIl0sInJvbGVzIjpbInJlYWRlciIsIndyaXRlciJdLCJyZXNvdXJjZXMiOlsiKjokVVNFUl9JRCQ6KiJdfSx7ImlkIjoicmlzay1tYW5hZ2VtZW50LWFwaSIsIm1ldGhvZHMiOlsicmlzay1tYW5hZ2VtZW50LWFwaTpyZXN0OnB1YmxpYzoqOioiXSwicm9sZXMiOlsicmVhZGVyIiwid3JpdGVyIl0sInJlc291cmNlcyI6WyIqOiRVU0VSX0lEJDoqIl19LHsiaWQiOiJjb3B5ZmFjdG9yeS1hcGkiLCJtZXRob2RzIjpbImNvcHlmYWN0b3J5LWFwaTpyZXN0OnB1YmxpYzoqOioiXSwicm9sZXMiOlsicmVhZGVyIiwid3JpdGVyIl0sInJlc291cmNlcyI6WyIqOiRVU0VSX0lEJDoqIl19LHsiaWQiOiJtdC1tYW5hZ2VyLWFwaSIsIm1ldGhvZHMiOlsibXQtbWFuYWdlci1hcGk6cmVzdDpkZWFsaW5nOio6KiIsIm10LW1hbmFnZXItYXBpOnJlc3Q6cHVibGljOio6KiJdLCJyb2xlcyI6WyJyZWFkZXIiLCJ3cml0ZXIiXSwicmVzb3VyY2VzIjpbIio6JFVTRVJfSUQkOioiXX0seyJpZCI6ImJpbGxpbmctYXBpIiwibWV0aG9kcyI6WyJiaWxsaW5nLWFwaTpyZXN0OnB1YmxpYzoqOioiXSwicm9sZXMiOlsicmVhZGVyIl0sInJlc291cmNlcyI6WyIqOiRVU0VSX0lEJDoqIl19XSwiaWdub3JlUmF0ZUxpbWl0cyI6ZmFsc2UsInRva2VuSWQiOiIyMDIxMDIxMyIsImltcGVyc29uYXRlZCI6ZmFsc2UsInJlYWxVc2VySWQiOiIyYTY2MGNmN2Q0ZWRlZDUzNzgwYTI2ZDcxODk2MjQ3NCIsImlhdCI6MTczNDU2NTk2MH0.ZVIKOvJ3Q9LLbrEf0QE1PdnYv6osSaB4mcUmg2Ma4q1hjEeKzeD37oWZ1ZxhtMZXbLHZDySiYoPt5A0sWmFxM_9i9rMnPE-BPpySFI-vnobOp-u9iWdZmyii7_EH3NTBuyDw_srL72H3s7nDOykQ4dwp7AnwFmfdWjdrmxu2wdu6fMZXgZLGgvPmX4Z6tPXi-3dTRV7wjjh87uOi3Ls9_TVlz5FaLVC438wAwLrRZyO8j5RYz4ufKBk5Jl008doFMoxaoe5fBndR9AcDBAlGZz51k7Ln0D8w1W5O0V9QrdUYm54xB9ZobTnWRsSlyWn0ywvn-hPHya-76T8gmp-okNBlG3pcbDSbB9bWLWnOCoYtaq1s-jvo1rZwtDpaCGikTOb1B1EClnVv-cxHv-yZfVqjAIJB4t86Ru3U5EOMqwhUaXrUOEPwevBe7yAOZazBqHvMj8ridEmAo0ZCkFQtWJol0tYD-HQfbiytmGot-8C8Dw7fnkDB-zo2CFt1yKyCQxeYs8hMIGYZ-lHOFUK1HINB9A8e9Uj5WMTX7URaRigiQsffr77uUFHFRbcTLSdXgKfwBHHp8Poet-2mryGNBjZuWN4Z7iq6nNyQV45r7JaRHBJxpzEVL0EEi4mrX6seSlZx5IbHJ8t7myGKzgpLWf6F_50aANQ33Y4qEjn3_I4'
TEST_ACCOUNT = '573b4688-0b9d-4b26-b38d-742de1248235'

import asyncio
import os
import json
from metaapi_cloud_sdk import MetaApi
from datetime import datetime, timedelta
from pprint import pprint
from collections import defaultdict
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def process_deals(deals):
    """
    Processes a list of deals and groups them by positionId to create a structured
    dictionary for each position with the required fields.
    """
    positions = {}
    
    # Group deals by positionId
    deals_by_position = defaultdict(list)
    for deal in deals:
        if not isinstance(deal, dict):
            logging.warning(f"Expected deal to be a dict, got {type(deal)}. Skipping.")
            continue
        position_id = deal.get('positionId')
        if position_id:
            deals_by_position[position_id].append(deal)
        else:
            logging.warning(f"Deal without positionId found: {deal}. Skipping.")
    
    # Process each position group
    for position_id, position_deals in deals_by_position.items():
        position = {
            'positionId': position_id,
            'symbol': None,
            'volume': None,
            'type': None,
            'openTime': None,
            'openPrice': None,
            'stopLoss': None,
            'takeProfit': None,
            'closeTime': None,
            'closePrice': None,
            'profit': 0.0
        }
        
        # Initialize variables to accumulate profit components
        total_commission = 0.0
        total_swap = 0.0
        total_profit = 0.0
        
        for deal in position_deals:
            deal_type = deal.get('type')
            entry_type = deal.get('entryType')
            
            # Set symbol and volume from any deal (assuming they are consistent)
            if not position['symbol']:
                position['symbol'] = deal.get('symbol', 'N/A')
            if not position['volume']:
                position['volume'] = deal.get('volume', 0.0)
            
            # Determine position type based on the first DEAL_ENTRY_IN deal
            if entry_type == 'DEAL_ENTRY_IN' and not position['type']:
                position['type'] = 'BUY' if deal_type == 'DEAL_TYPE_BUY' else 'SELL'
                position['openTime'] = deal['time'].isoformat() if 'time' in deal else 'N/A'
                position['openPrice'] = deal.get('price', 0.0)
            
            # Extract stopLoss and takeProfit from DEAL_ENTRY_OUT
            if entry_type == 'DEAL_ENTRY_OUT':
                position['stopLoss'] = deal.get('stopLoss', 'N/A')
                position['takeProfit'] = deal.get('takeProfit', 'N/A')
                position['closeTime'] = deal['time'].isoformat() if 'time' in deal else 'N/A'
                position['closePrice'] = deal.get('price', 0.0)
            
            # Accumulate profit components
            total_commission += deal.get('commission', 0.0)
            total_swap += deal.get('swap', 0.0)
            total_profit += deal.get('profit', 0.0)
        
        # Calculate total profit as sum of commission, swap, and profit
        position['profit'] = round(total_commission + total_swap + total_profit, 2)
        
        positions[position_id] = position
    
    return list(positions.values())

async def meta_api_synchronization():
    api = MetaApi(TOKEN)
    try:
        # Retrieve account
        account = await api.metatrader_account_api.get_account(TEST_ACCOUNT) 

        # Wait until connected
        await account.wait_connected()
        logging.info("Connected to MetaApi account.")

        # Get RPC connection
        connection = account.get_rpc_connection()

        # Connect and synchronize
        await connection.connect()
        logging.info("Connected to MetaApi RPC.")

        await connection.wait_synchronized()
        logging.info("MetaApi RPC synchronized.")

        # Fetch deals within the last 90 days
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=90)
        
        deals_response = await connection.get_deals_by_time_range(start_time, end_time)
        deals = deals_response.get('deals', [])
        
        if not deals:
            logging.info("No deals found in the last 90 days.")
        else:
            # Process deals to group them into positions
            positions = process_deals(deals)
    
            # Display the raw deals
            logging.info('History Deals (Last 90 Days):\n')
            pprint(deals)
            print("") 
    
            # Display the processed positions
            logging.info('History Positions (Last 90 Days):\n')
            pprint(positions)
            print("")
    
            # Optionally, save the positions to a JSON file
            with open('processed_positions.json', 'w') as f:
                json.dump(positions, f, indent=4, default=str)  # default=str to handle datetime serialization
            logging.info("Processed positions saved to 'processed_positions.json'\n")
    
        # Close the connection
        await connection.close()
        logging.info("MetaApi RPC connection closed.")
    
    except Exception as err:
        # Process errors
        if hasattr(err, 'details'):
            if err.details == 'E_SRV_NOT_FOUND':
                logging.error("Error: Server not found. Please check the server name or provisioning profile.")
            elif err.details == 'E_AUTH':
                logging.error("Error: Authentication failed. Please verify your login and password.")
            elif err.details == 'E_SERVER_TIMEZONE':
                logging.error("Error: Server timezone issue. Try again later or adjust your settings.")
            else:
                logging.error(f"Unhandled error detail: {err.details}")
        else:
            logging.error("An unexpected error occurred:")
            logging.error(api.format_error(err))
    finally:
        exit()

# Run the asynchronous main function
if __name__ == "__main__":
    asyncio.run(meta_api_synchronization())
